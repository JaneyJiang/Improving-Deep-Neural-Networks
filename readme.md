## Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization

About this Course
This course will teach you the "magic" of getting deep learning to work well. Rather than the deep learning process being a black box, you will understand what drives performance, and be able to more systematically get good results. You will also learn TensorFlow.

After 3 weeks, you will:
- Understand industry best-practices for building deep learning applications.
- Be able to effectively use the common neural network "tricks", including initialization, L2 and dropout regularization, Batch normalization, gradient checking,
- Be able to implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence.
- Understand new best-practices for the deep learning era of how to set up train/dev/test sets and analyze bias/variance
- Be able to implement a neural network in TensorFlow.

This is the second course of the Deep Learning Specialization.

### WEEK 1
#### Practical aspects of Deep Learning
15 videos
###### Graded: Practical aspects of deep learning
###### Graded: Initialization
###### Graded: Regularization
###### Graded: Gradient Checking

### WEEK 2
#### Optimization algorithms
11 videos
###### Graded: Optimization algorithms
###### Graded: Optimization

### WEEK 3
##### Hyperparameter tuning, Batch Normalization and Programming Frameworks
11 videos
###### Graded: Hyperparameter tuning, Batch Normalization, Programming 
Frameworks
###### Graded: Tensorflow
